{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2617192,
          "sourceType": "datasetVersion",
          "datasetId": 1590810
        }
      ],
      "dockerImageVersionId": 30301,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31d9e314ece54ded9ecba9e7d0224da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_040f5827c5874cada2fe4c2f9aeb0aec",
              "IPY_MODEL_103c2696a74b413ba086aa4dc1e988b8",
              "IPY_MODEL_3d4726d8067a45f9a77cdbffcbd053d3"
            ],
            "layout": "IPY_MODEL_cdbc34ce0b99407f977403d79530279d"
          }
        },
        "040f5827c5874cada2fe4c2f9aeb0aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14a13362dd94c6aaa2165febeeded9b",
            "placeholder": "​",
            "style": "IPY_MODEL_af936f2f23a8415ca7bfd824c4b028f2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "103c2696a74b413ba086aa4dc1e988b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_820e8f6350244006859ab57fc4944e38",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_392f506eb46847f9896f10e57cc4fb82",
            "value": 48
          }
        },
        "3d4726d8067a45f9a77cdbffcbd053d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6836a767f3d14d3788e78a293750de56",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ee0aaecfa54a0daedc193b45102396",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.35kB/s]"
          }
        },
        "cdbc34ce0b99407f977403d79530279d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14a13362dd94c6aaa2165febeeded9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af936f2f23a8415ca7bfd824c4b028f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820e8f6350244006859ab57fc4944e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392f506eb46847f9896f10e57cc4fb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6836a767f3d14d3788e78a293750de56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ee0aaecfa54a0daedc193b45102396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f53dbf488149aab6eb8a3c96d4ce36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db49571582af4f83b25e42f10f84d066",
              "IPY_MODEL_fda1b4aa4e754969a5d33c579f996337",
              "IPY_MODEL_b58a1011d7914d368e38b1ba70b7e28c"
            ],
            "layout": "IPY_MODEL_3bc356012a7346888dd7dc8878e1413e"
          }
        },
        "db49571582af4f83b25e42f10f84d066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1818823403904c1f875478a709d3900c",
            "placeholder": "​",
            "style": "IPY_MODEL_88860ae697b6448388fe9ca8f72eed2f",
            "value": "vocab.txt: 100%"
          }
        },
        "fda1b4aa4e754969a5d33c579f996337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8135bdb617374552bdbcae03e5481242",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7793b3b7964b445283613dfc944d4edd",
            "value": 231508
          }
        },
        "b58a1011d7914d368e38b1ba70b7e28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d623964178b44d4afaa8095abb779e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d33066c2a35447998d17ed3e869a60db",
            "value": " 232k/232k [00:00&lt;00:00, 647kB/s]"
          }
        },
        "3bc356012a7346888dd7dc8878e1413e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1818823403904c1f875478a709d3900c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88860ae697b6448388fe9ca8f72eed2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8135bdb617374552bdbcae03e5481242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7793b3b7964b445283613dfc944d4edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d623964178b44d4afaa8095abb779e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33066c2a35447998d17ed3e869a60db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275cd270bba14cc69fdc06ee424433fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5786792020c94ebcaf04dcfdd709e7a3",
              "IPY_MODEL_ed26eb68a3a549ae8ee1874932cd8c7c",
              "IPY_MODEL_bbaa7da3c2dd4d8a9794a849904594ae"
            ],
            "layout": "IPY_MODEL_25c1e16268354a7097326cc20f265039"
          }
        },
        "5786792020c94ebcaf04dcfdd709e7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944a1745c0bd41ebb9034ba08f712b92",
            "placeholder": "​",
            "style": "IPY_MODEL_9b935ff35fde41ba81ba8e8f8d46e72e",
            "value": "tokenizer.json: 100%"
          }
        },
        "ed26eb68a3a549ae8ee1874932cd8c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7188b9cf89f0459fba53574898e72c8d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2172e9eb23df44e4b9325946f5ed822a",
            "value": 466062
          }
        },
        "bbaa7da3c2dd4d8a9794a849904594ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6604b0d4628a43abb8a59d9de376676c",
            "placeholder": "​",
            "style": "IPY_MODEL_d461010cd0284924b66830e22d9a78b4",
            "value": " 466k/466k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "25c1e16268354a7097326cc20f265039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944a1745c0bd41ebb9034ba08f712b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b935ff35fde41ba81ba8e8f8d46e72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7188b9cf89f0459fba53574898e72c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2172e9eb23df44e4b9325946f5ed822a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6604b0d4628a43abb8a59d9de376676c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d461010cd0284924b66830e22d9a78b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitorLima2521/Twitter-Emotion-Classification/blob/main/Twitter_Emotion_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "parulpandey_emotion_dataset_path = kagglehub.dataset_download('parulpandey/emotion-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "366lDDXDHctY",
        "outputId": "9ac16321-8bc3-4d21-a22b-ff4bf9c0c78d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/parulpandey/emotion-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 715k/715k [00:00<00:00, 1.10MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/KOjXRJg.jpg)\n",
        "\n",
        "### <b><span style='color:#F1A424'>Test Classification</span></b>\n",
        "\n",
        "- A classificação de texto é uma das tarefas mais comuns em PNL\n",
        "- Ele pode ser usado para uma ampla gama de aplicações (por exemplo, marcar o feedback do cliente em categorias, encaminhar tickets de suporte de acordo com o idioma)\n",
        "- Outro tipo comum de problema de classificação de texto é **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">sentiment analysis</mark>** que visa **identificar a polaridade** de um determinado texto (+/-)\n",
        "\n",
        "### <b><span style='color:#F1A424'>Nossa Tarefa</span></b>\n",
        "\n",
        "- Precisamos construir um sistema que seja capaz de identificar automaticamente estados emocionais (por exemplo, raiva, alegria) que as pessoas expressam sobre o produto da sua empresa no Twitter.\n",
        "- Para esta tarefa, usaremos uma variante de **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">BERT</mark>**; **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>**, a principal vantagem deste modelo é que ele é muito menor que **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">BERT</mark>** (ou seja, mais eficiente), mas é capaz de atingir um desempenho comparável\n",
        "- Usaremos três bibliotecas principais do **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Hugging Face</mark>** ecossistema: **<span style='color:#FFC300'>Datasets</span>**, **<span style='color:#FFC300'>Tokenizers</span>** & **<span style='color:#FFC300'>Transformers</span>**"
      ],
      "metadata": {
        "id": "w_fMz493Hctb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>1 |</span></b> <b>O DATASET</b></div>\n",
        "    \n",
        "- Muitos conjuntos de dados que envolvem análise de sentimentos são problemas de classificação binária.\n",
        "- Neste conjunto de dados, temos 6 sentimentos diferentes, o que significa que trataremos este problema como um problema de classificação multiclasse."
      ],
      "metadata": {
        "id": "DoeSVYzIHctd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/emotion-dataset/"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T16:36:55.48549Z",
          "iopub.execute_input": "2022-12-08T16:36:55.485896Z",
          "iopub.status.idle": "2022-12-08T16:36:56.511526Z",
          "shell.execute_reply.started": "2022-12-08T16:36:55.485863Z",
          "shell.execute_reply": "2022-12-08T16:36:56.510324Z"
        },
        "trusted": true,
        "id": "HBVO9C6ZHctd",
        "outputId": "aa24e57c-4110-4002-f2f7-f29b1e5a12d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/kaggle/input/emotion-dataset/': No such file or directory\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import panel as pn\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "def show_panel(df):\n",
        "    return pn.widgets.Tabulator(df.head(20),\n",
        "                    show_index=False,\n",
        "                    pagination='local',\n",
        "                         page_size=10)\n",
        "\n",
        "\n",
        "pn.extension('tabulator')\n",
        "pn.widgets.Tabulator.theme = 'bootstrap'\n",
        "\n",
        "validation = pd.read_csv('/kaggle/input/emotion-dataset/validation.csv')\n",
        "train = pd.read_csv('/kaggle/input/emotion-dataset/training.csv')\n",
        "test = pd.read_csv('/kaggle/input/emotion-dataset/test.csv')\n",
        "\n",
        "print('Dataset information:')\n",
        "print(f'Training data: {train.shape}')\n",
        "print(f'Validation data: {validation.shape}')\n",
        "print(f'Test data: {test.shape}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:25:52.326001Z",
          "iopub.execute_input": "2023-04-24T06:25:52.326424Z",
          "iopub.status.idle": "2023-04-24T06:25:52.424508Z",
          "shell.execute_reply.started": "2023-04-24T06:25:52.326379Z",
          "shell.execute_reply": "2023-04-24T06:25:52.423439Z"
        },
        "trusted": true,
        "id": "V1FGF51rHctd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_panel(train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:25:55.517135Z",
          "iopub.execute_input": "2023-04-24T06:25:55.517881Z",
          "iopub.status.idle": "2023-04-24T06:25:55.551513Z",
          "shell.execute_reply.started": "2023-04-24T06:25:55.517838Z",
          "shell.execute_reply": "2023-04-24T06:25:55.550507Z"
        },
        "trusted": true,
        "id": "yVszXzH5Hcte"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Combinar DataFrames em Dataset</span></b>\n",
        "- Pode ser mais intuitivo utilizar o conjunto de dados do **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">HuggingFace</mark>**'s Dataset"
      ],
      "metadata": {
        "id": "-hKE4CQ2Hcte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset,DatasetDict,Features,Value,ClassLabel\n",
        "\n",
        "# Don't forget the class label data\n",
        "class_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
        "ft = Features({'text': Value('string'), 'label': ClassLabel(names=class_names)})\n",
        "\n",
        "# Combine Multiple Datasets\n",
        "emotions = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train,features=ft),\n",
        "    \"test\": Dataset.from_pandas(test,features=ft),\n",
        "    \"validation\": Dataset.from_pandas(validation,features=ft)\n",
        "    })\n",
        "\n",
        "# Convert a single DataFrame to a Dataset\n",
        "# emotions = Dataset.from_pandas(train,features=ft)\n",
        "\n",
        "emotions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:26:52.794795Z",
          "iopub.execute_input": "2023-04-24T06:26:52.795156Z",
          "iopub.status.idle": "2023-04-24T06:26:53.410131Z",
          "shell.execute_reply.started": "2023-04-24T06:26:52.795124Z",
          "shell.execute_reply": "2023-04-24T06:26:53.409252Z"
        },
        "trusted": true,
        "id": "vld4abPlHctf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Selecionando um subconjunto</span></b>\n",
        "- Trabalharemos com o conjunto de dados de treinamento e validação neste problema.\n",
        "- Vamos mostrar algumas características úteis da classe **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Dataset</mark>**"
      ],
      "metadata": {
        "id": "bGho08PAHctg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:26:55.920405Z",
          "iopub.execute_input": "2023-04-24T06:26:55.920934Z",
          "iopub.status.idle": "2023-04-24T06:26:55.928537Z",
          "shell.execute_reply.started": "2023-04-24T06:26:55.920904Z",
          "shell.execute_reply": "2023-04-24T06:26:55.92743Z"
        },
        "trusted": true,
        "id": "yKyPTBxYHctg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get First 5 Entries in Dictionary Format (Group them)\n",
        "train_ds[:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:26:58.659194Z",
          "iopub.execute_input": "2023-04-24T06:26:58.659574Z",
          "iopub.status.idle": "2023-04-24T06:26:58.669467Z",
          "shell.execute_reply.started": "2023-04-24T06:26:58.659543Z",
          "shell.execute_reply": "2023-04-24T06:26:58.668508Z"
        },
        "trusted": true,
        "id": "0M3KpLayHctg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Conversão de conjunto de dados em DataFrame</span></b>\n",
        "- Sempre que precisamos de um pandas `DataFrame`, por exemplo, para visualizações, Sempre que precisamos de um DataFrame pandas, por exemplo, para visualizações, podemos utilizar o método ''  `Dataset`'' `.set_format`"
      ],
      "metadata": {
        "id": "PRPH9BywHcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Dataset to DataFrame (don't forget to reset)\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "show_panel(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:27:31.05733Z",
          "iopub.execute_input": "2023-04-24T06:27:31.057937Z",
          "iopub.status.idle": "2023-04-24T06:27:31.10033Z",
          "shell.execute_reply.started": "2023-04-24T06:27:31.057901Z",
          "shell.execute_reply": "2023-04-24T06:27:31.099419Z"
        },
        "trusted": true,
        "id": "quhKdNYXHcth"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Adicionando dados de rótulo</span></b>\n",
        "- Certificamo-nos de não esquecer os `label_names` ao converter de `DataFrame` para `Dataset`\n",
        "- Podemos converter valores **numéricos** em valores de **string** usando o método `int2str`"
      ],
      "metadata": {
        "id": "cKksl5WZHcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add label data to dataframe\n",
        "def label_int2str(row):\n",
        "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "show_panel(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:30:10.073042Z",
          "iopub.execute_input": "2023-04-24T06:30:10.07342Z",
          "iopub.status.idle": "2023-04-24T06:30:10.146886Z",
          "shell.execute_reply.started": "2023-04-24T06:30:10.073363Z",
          "shell.execute_reply": "2023-04-24T06:30:10.144992Z"
        },
        "trusted": true,
        "id": "vejXu4h4Hcth"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>2 |</span></b> <b>DISTRIBUIÇÃO DE CLASSES</b></div>\n",
        "\n",
        "- Nosso conjunto de dados tem 6 classes `joy`, `sadness`, `anger`, `fear`, `love` e `surprise`; problema multiclasse"
      ],
      "metadata": {
        "id": "1zvQZjkOHcti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "px.bar(df['label_name'].value_counts(ascending=True),template='plotly_white')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-24T06:30:21.363191Z",
          "iopub.execute_input": "2023-04-24T06:30:21.363567Z",
          "iopub.status.idle": "2023-04-24T06:30:23.857696Z",
          "shell.execute_reply.started": "2023-04-24T06:30:21.363535Z",
          "shell.execute_reply": "2023-04-24T06:30:23.856812Z"
        },
        "trusted": true,
        "id": "cv_PagnZHcti"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>3 |</span></b> <b>DURAÇÃO DE CADA TWEET</b></div>\n",
        "\n",
        "- Para aplicações que utilizam **DistilBERT**, o tamanho máximo do contexto é **512 tokens**\n",
        "- A maioria dos tweets tem entre **10 e 20 palavras**, o que se enquadra perfeitamente nesse limite"
      ],
      "metadata": {
        "id": "x85NxN3_Hcti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "\n",
        "px.box(df,y='Words Per Tweet',\n",
        "       color='label_name',\n",
        "       template='plotly_white')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:17.381262Z",
          "iopub.execute_input": "2022-12-08T10:22:17.382365Z",
          "iopub.status.idle": "2022-12-08T10:22:17.556857Z",
          "shell.execute_reply.started": "2022-12-08T10:22:17.382327Z",
          "shell.execute_reply": "2022-12-08T10:22:17.555669Z"
        },
        "trusted": true,
        "id": "jN7L7vh8Hcti"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>4 |</span></b> <b>TOKENIZAÇÃO</b></div>\n",
        "\n",
        "- Assim como outros modelos, o **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>** não pode receber strings python brutas como entrada\n",
        "- Em vez disso, precisamos dividir as strings em subgrupos chamados **tokens** e codificá-los como **vetores numéricos**\n",
        "- Vamos considerar dois tipos de abordagens de **tokenização**: **<span style='color:#FFC300'>caracteres</span>** & **<span style='color:#FFC300'>palavras</span>** tokenização"
      ],
      "metadata": {
        "id": "C1LsT0pcHcti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 4.1 | </span>Character Tokenização </b>\n",
        "\n",
        "A abordagem de tokenização mais simples é a **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">character tokenisation</mark>**, podemos usar a classe de lista interna do Python"
      ],
      "metadata": {
        "id": "ML5zubIfHcti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Tokenisation of text is a core task of NLP.'\n",
        "tokenised_text = list(text)\n",
        "\n",
        "# Character Tokenised list\n",
        "print(f'Number of tokens: {len(tokenised_text)}')\n",
        "print(tokenised_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:17.561223Z",
          "iopub.execute_input": "2022-12-08T10:22:17.562103Z",
          "iopub.status.idle": "2022-12-08T10:22:17.571684Z",
          "shell.execute_reply.started": "2022-12-08T10:22:17.562066Z",
          "shell.execute_reply": "2022-12-08T10:22:17.57029Z"
        },
        "trusted": true,
        "id": "SiZQ5hOuHcti"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converter cada caractere em um inteiro (numericalização)\n",
        "- `token2idx` nos dá um mapeamento de cada caractere no **vocabulário** para um inteiro único"
      ],
      "metadata": {
        "id": "lG_5Y-qHHctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping Vecabulary dictionary\n",
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenised_text)))}\n",
        "\n",
        "print(f'Length of vocabulary: {len(token2idx)}')\n",
        "print(token2idx)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:17.57347Z",
          "iopub.execute_input": "2022-12-08T10:22:17.573964Z",
          "iopub.status.idle": "2022-12-08T10:22:17.580955Z",
          "shell.execute_reply.started": "2022-12-08T10:22:17.573925Z",
          "shell.execute_reply": "2022-12-08T10:22:17.579745Z"
        },
        "trusted": true,
        "id": "LV2imo39Hctj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Reconstruindo texto</span></b>\n",
        "- Uma vez que temos um dicionário de vocabulário, podemos reconstruir"
      ],
      "metadata": {
        "id": "oha-AkGwHctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's represent text in numerical format\n",
        "input_ids = [token2idx[token] for token in tokenised_text]\n",
        "\n",
        "print(f'{len(input_ids)} characters')\n",
        "print(input_ids)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:17.582703Z",
          "iopub.execute_input": "2022-12-08T10:22:17.583123Z",
          "iopub.status.idle": "2022-12-08T10:22:17.595424Z",
          "shell.execute_reply.started": "2022-12-08T10:22:17.583088Z",
          "shell.execute_reply": "2022-12-08T10:22:17.594283Z"
        },
        "trusted": true,
        "id": "WvO4vT1JHctj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Convert to OHE</span></b>\n",
        "\n",
        "- O último passo é converter `input_ids` em um tensor 2D de vetores one-hot, vamos usar o pytorch abaixo\n",
        "- Os vetores One-Hot são frequentemente usados ​​em aplicações de ML para codificar **dados categóricos** (ordinais ou nominais)\n",
        "- Para cada um dos 42 tokens de entrada, agora temos um vetor one-hot com 18 dimensões (tamanho do vocabulário)"
      ],
      "metadata": {
        "id": "Z9DYJZxjHctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "inputs_ids = torch.tensor(input_ids)\n",
        "one_hot_encodings = F.one_hot(inputs_ids,num_classes = len(token2idx))\n",
        "print(f'OHE size: {one_hot_encodings.shape}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:17.597052Z",
          "iopub.execute_input": "2022-12-08T10:22:17.597471Z",
          "iopub.status.idle": "2022-12-08T10:22:19.046628Z",
          "shell.execute_reply.started": "2022-12-08T10:22:17.597436Z",
          "shell.execute_reply": "2022-12-08T10:22:19.04555Z"
        },
        "trusted": true,
        "id": "GU82N8oFHctj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Desvantagens da Tokenização de Caracteres</span></b>\n",
        "\n",
        "- A tokenização em nível de caractere ignora qualquer estrutura no texto e trata toda a sequência como um fluxo de caracteres\n",
        "- Isso ajuda a lidar com erros ortográficos e palavras repetidas, mas a principal desvantagem é que as estruturas linguísticas precisam ser aprendidas a partir dos dados\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Character tokenisation</mark>** raramente é usado na prática, em vez disso, alguma estrutura do texto é preservada se utilizarmos **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Word Tokenisation</mark>**"
      ],
      "metadata": {
        "id": "GEHzJKSaHctj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 4.2 | </span>Tokenização de palavras </b>\n",
        "\n",
        "- Em vez de dividir o texto em caracteres, podemos dividi-lo em palavras e mapear cada palavra para um inteiro.\n",
        "- A forma mais simples de tokenização é se utilizarmos o método de divisão de classe de string embutido do Python\n",
        "- Ao contrário **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Character tokenisation</mark>**, se tivermos declinações, conjugações e erros ortográficos, o tamanho do dicionário de vocabulário pode aumentar muito rapidamente.\n",
        "- **Vocabulários** maiores são um problema, porque exigem que o modelo tenha um excesso de parâmetros (o que é ineficiente)\n",
        "\n",
        "\n",
        "- É comum selecionar as 100.000 palavras mais comuns no corpus\n",
        "- palavras que não fazem parte do vocabulário são classificadas como desconhecidas e mapeadas para um token**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">UNK</mark>** compartilhado\n",
        "- No entanto, pode potencialmente perder algumas informações importantes durante o processo de tokenização, uma vez que o modelo não possui informações sobre palavras associadas a **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">UNK</mark>**"
      ],
      "metadata": {
        "id": "vukXJEesHctk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenised_text = text.split()\n",
        "print(tokenised_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:19.048502Z",
          "iopub.execute_input": "2022-12-08T10:22:19.049495Z",
          "iopub.status.idle": "2022-12-08T10:22:19.055127Z",
          "shell.execute_reply.started": "2022-12-08T10:22:19.049456Z",
          "shell.execute_reply": "2022-12-08T10:22:19.054067Z"
        },
        "trusted": true,
        "id": "m8Zxry46Hctk",
        "outputId": "c61a72ac-b1e1-4cf4-9a4e-43dc3449a99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenisation', 'of', 'text', 'is', 'a', 'core', 'task', 'of', 'NLP.']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 4.3 | </span>Tokenização de subpalavra </b>\n",
        "\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Subword tokenization</mark>** é combinar os melhores aspectos da tokenização de  **<span style='color:#FFC300'>caracteres</span>** & **<span style='color:#FFC300'>palavra</span>**\n",
        "- A principal característica distintiva de **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Subword tokenization</mark>** é que ele é aprendido a partir de um corpus de pré-treinamento usando uma mistura de regras estatísticas e algoritmos\n",
        "\n",
        "\n",
        "- Existem vários **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Subword tokenization</mark>**algoritmos comumente usados ​​em NLP\n",
        "    - vamos começar com `WordPiece`, que é usado pelo `BERT` e `DistilBERT` tokenizadores\n",
        "    \n",
        "\n",
        "- `AutoTokenizer` a classe nos permite carregar rapidamente o tokenizador associado a um modelo pré-treinado\n",
        "- Ou podemos carregar o Tokeniser manualmente a partir de `transformers.DistilBertTokenizer`\n",
        "\n"
      ],
      "metadata": {
        "id": "gYIFMhRIHctk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "text = 'Tokenisation of text is a core task of NLP.'\n",
        "\n",
        "# Load parameters of the tokeniser\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Show tokeniser information\n",
        "tokenizer\n",
        "\n",
        "# Or we can load the Tokeniser manually `transformers.DistilBertTokenizer`\n",
        "\n",
        "# from transformers import DistilBertTokenizer\n",
        "\n",
        "# model_ckpt = \"distilbert-base-uncased\"\n",
        "# distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)\n",
        "# distilbert_tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:19.056725Z",
          "iopub.execute_input": "2022-12-08T10:22:19.057642Z",
          "iopub.status.idle": "2022-12-08T10:22:34.711552Z",
          "shell.execute_reply.started": "2022-12-08T10:22:19.057587Z",
          "shell.execute_reply": "2022-12-08T10:22:34.710509Z"
        },
        "trusted": true,
        "id": "MvuW8jl3Hctk",
        "outputId": "7bc81a26-b144-40bb-8b21-91456b8afc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "31d9e314ece54ded9ecba9e7d0224da0",
            "040f5827c5874cada2fe4c2f9aeb0aec",
            "103c2696a74b413ba086aa4dc1e988b8",
            "3d4726d8067a45f9a77cdbffcbd053d3",
            "cdbc34ce0b99407f977403d79530279d",
            "c14a13362dd94c6aaa2165febeeded9b",
            "af936f2f23a8415ca7bfd824c4b028f2",
            "820e8f6350244006859ab57fc4944e38",
            "392f506eb46847f9896f10e57cc4fb82",
            "6836a767f3d14d3788e78a293750de56",
            "b9ee0aaecfa54a0daedc193b45102396",
            "90f53dbf488149aab6eb8a3c96d4ce36",
            "db49571582af4f83b25e42f10f84d066",
            "fda1b4aa4e754969a5d33c579f996337",
            "b58a1011d7914d368e38b1ba70b7e28c",
            "3bc356012a7346888dd7dc8878e1413e",
            "1818823403904c1f875478a709d3900c",
            "88860ae697b6448388fe9ca8f72eed2f",
            "8135bdb617374552bdbcae03e5481242",
            "7793b3b7964b445283613dfc944d4edd",
            "7d623964178b44d4afaa8095abb779e6",
            "d33066c2a35447998d17ed3e869a60db",
            "275cd270bba14cc69fdc06ee424433fb",
            "5786792020c94ebcaf04dcfdd709e7a3",
            "ed26eb68a3a549ae8ee1874932cd8c7c",
            "bbaa7da3c2dd4d8a9794a849904594ae",
            "25c1e16268354a7097326cc20f265039",
            "944a1745c0bd41ebb9034ba08f712b92",
            "9b935ff35fde41ba81ba8e8f8d46e72e",
            "7188b9cf89f0459fba53574898e72c8d",
            "2172e9eb23df44e4b9325946f5ed822a",
            "6604b0d4628a43abb8a59d9de376676c",
            "d461010cd0284924b66830e22d9a78b4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31d9e314ece54ded9ecba9e7d0224da0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90f53dbf488149aab6eb8a3c96d4ce36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "275cd270bba14cc69fdc06ee424433fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print('')\n",
        "print(f'Vocab size: {tokenizer.vocab_size}')\n",
        "print(f'Max length: {tokenizer.model_max_length}')\n",
        "print(f'Tokeniser model input names: {tokenizer.model_input_names}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.713058Z",
          "iopub.execute_input": "2022-12-08T10:22:34.713405Z",
          "iopub.status.idle": "2022-12-08T10:22:34.720253Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.713368Z",
          "shell.execute_reply": "2022-12-08T10:22:34.719269Z"
        },
        "trusted": true,
        "id": "ujZFSBOUHctk",
        "outputId": "f82afcf1-11b3-4fcc-e993-aecf92619a0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocab size: 30522\n",
            "Max length: 512\n",
            "Tokeniser model input names: ['input_ids', 'attention_mask']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print('Encoded text')\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text,'\\n')\n",
        "\n",
        "print('Tokens')\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens,'\\n')\n",
        "\n",
        "print('Convert tokens to string')\n",
        "print(tokenizer.convert_tokens_to_string(tokens),'\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.721795Z",
          "iopub.execute_input": "2022-12-08T10:22:34.722771Z",
          "iopub.status.idle": "2022-12-08T10:22:34.736364Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.722735Z",
          "shell.execute_reply": "2022-12-08T10:22:34.735234Z"
        },
        "trusted": true,
        "id": "doqqgaPDHctk",
        "outputId": "2f88b850-ec90-45bc-c0e8-f7332d4f570e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded text\n",
            "{'input_ids': [101, 19204, 6648, 1997, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
            "\n",
            "Tokens\n",
            "['[CLS]', 'token', '##isation', 'of', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]'] \n",
            "\n",
            "Convert tokens to string\n",
            "[CLS] tokenisation of text is a core task of nlp. [SEP] \n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.737582Z",
          "iopub.execute_input": "2022-12-08T10:22:34.738047Z",
          "iopub.status.idle": "2022-12-08T10:22:34.743575Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.738013Z",
          "shell.execute_reply": "2022-12-08T10:22:34.742657Z"
        },
        "trusted": true,
        "id": "p0TLs8BBHctl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 4.4 | </span>Tokenização de todo o conjunto de dados </b>\n",
        "\n",
        "- Ao lidar com texto de tamanhos diferentes, o tokenizador irá **<span style='color:#FFC300'>pad</span>** frases de comprimento insuficiente se **padding** é selecionado\n",
        "- O **comprimento máximo** dos dados tokenizados será o **comprimento do tweet mais longo** (por exemplo, 2ª linha)\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Attention mask</mark>** ajuda o modelo a entender quais partes da frase ignorar"
      ],
      "metadata": {
        "id": "O_rLZwFzHctl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisation function\n",
        "def tokenise(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "# Show the tokenised ids\n",
        "ex_tokenised = tokenise(emotions[\"train\"][:2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.745304Z",
          "iopub.execute_input": "2022-12-08T10:22:34.746176Z",
          "iopub.status.idle": "2022-12-08T10:22:34.752625Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.74614Z",
          "shell.execute_reply": "2022-12-08T10:22:34.751675Z"
        },
        "trusted": true,
        "id": "E0lH2lJgHctl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Show attention mask\n",
        "ex_tokenised['attention_mask']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.754148Z",
          "iopub.execute_input": "2022-12-08T10:22:34.754846Z",
          "iopub.status.idle": "2022-12-08T10:22:34.762483Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.754811Z",
          "shell.execute_reply": "2022-12-08T10:22:34.761559Z"
        },
        "trusted": true,
        "id": "ohLenZTZHctl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# apply to the entire dataset (train,test and validation dataset)\n",
        "emotions_encoded = emotions.map(tokenise, batched=True, batch_size=None)\n",
        "print(emotions_encoded[\"train\"].column_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:34.763772Z",
          "iopub.execute_input": "2022-12-08T10:22:34.764332Z",
          "iopub.status.idle": "2022-12-08T10:22:37.346879Z",
          "shell.execute_reply.started": "2022-12-08T10:22:34.764293Z",
          "shell.execute_reply": "2022-12-08T10:22:37.345969Z"
        },
        "trusted": true,
        "id": "mhW0y2PYHctv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>5 |</span></b> <b>TRENANDO UM CLASSIFICADOR DE TEXTO</b></div>\n",
        "\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>** esse modelos **são pré-treinados para prever palavras mascaradas em uma frase de texto.**\n",
        "- Não podemos usar esses modelos de linguagem diretamente para classificação de texto, sendo necessárias algumas pequenas modificações.\n",
        "\n",
        "\n",
        "- Primeiramente, o texto é tokenizado, representado usando vetores one-hot chamados **token encodings**\n",
        "- O tamanho do vocabulário do tokenizador determina a dimensão da próxima codificação (geralmente 20-200k)\n",
        "- Em seguida, essas codificações de token são convertidas em embeddings de token (vetores que residem em um espaço dimensional inferior).\n",
        "- Os embeddings de token são então passados ​​pelas camadas de blocos do codificador para produzir um estado oculto para cada token de entrada.\n",
        "*Para o objetivo pré-treinado de modelagem de linguagem, cada estado oculto é alimentado a uma camada que prevê os tokens de entrada mascarados.\n",
        "* Para a tarefa de classificação, substituímos a camada de modelagem de linguagem por uma camada de classificação.\n",
        "Temos duas opções para treinar esse modelo em nosso conjunto de dados:\n",
        "\n",
        "Temos duas opções para treinar esse modelo em nosso conjunto de dados:\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Feature Extraction</mark>** : Usamos os estados ocultos como características e apenas treinamos o classificador com base neles, sem modificar o modelo pré-treinado.\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Fine Tuning</mark>** : Treinamos todo o modelo, de ponta a ponta, que posteriormente também atualiza os parâmetros do modelo pré-treinado\n"
      ],
      "metadata": {
        "id": "xtI0iztCHctv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 5.1 | </span>Transformers as feature extractors </b>\n",
        "\n",
        "### **<span style='color:#F1A424'>Modelos pré-treinados</span>**\n",
        "\n",
        "- Usaremos outra classe automatica `AutoModel`, similar ao `AutoTokenizer`\n",
        "- `AutoModel` possui o métado `from_pretrained` para carregar os pesos de um modelo prétreinado\n",
        "- A classe `AutoModel` converte as codificações de tokens em embeddings e os alimenta atrav´ws da pilha do codificador para retornar **estados ocultos**"
      ],
      "metadata": {
        "id": "Md4LjQYNHctw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:22:37.348191Z",
          "iopub.execute_input": "2022-12-08T10:22:37.352588Z",
          "iopub.status.idle": "2022-12-08T10:23:12.630645Z",
          "shell.execute_reply.started": "2022-12-08T10:22:37.35255Z",
          "shell.execute_reply": "2022-12-08T10:23:12.629591Z"
        },
        "trusted": true,
        "id": "keQV1P0THctw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<span style='color:#F1A424'>Extraindo o último estado ocultos</span>**\n",
        "estado oculto de uma única string **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">estado oculto</mark>**\n",
        "- Primeiro, codifica a string e converte os tokens em tesores PyToch\n",
        "- o tensor resultante tem o formato **[batch_size,n_tokens]**\n",
        "- Tnedo as codificações como tensores, a etapas é colocá-las no mesmo dispositivo que o modelo e passar as entradas:"
      ],
      "metadata": {
        "id": "6Cxeu4zvHctw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"this is a test\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:12.632534Z",
          "iopub.execute_input": "2022-12-08T10:23:12.632868Z",
          "iopub.status.idle": "2022-12-08T10:23:12.639303Z",
          "shell.execute_reply.started": "2022-12-08T10:23:12.632838Z",
          "shell.execute_reply": "2022-12-08T10:23:12.638337Z"
        },
        "trusted": true,
        "id": "GugeLXypHctw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dependendo da configuração do modelo, o modelo pode conter vários objetos (**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Hidden states</mark>**, **losses**, **attentions**, ...)\n",
        "- O modelo atual (`distilbert-base-uncased`) retorna apenas um atributo, que é o `last_hidden_state`"
      ],
      "metadata": {
        "id": "Jf7-MxS-Hctx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:12.64078Z",
          "iopub.execute_input": "2022-12-08T10:23:12.641371Z",
          "iopub.status.idle": "2022-12-08T10:23:14.489982Z",
          "shell.execute_reply.started": "2022-12-08T10:23:12.641332Z",
          "shell.execute_reply": "2022-12-08T10:23:14.488953Z"
        },
        "trusted": true,
        "id": "imQNfWPrHctx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- O tensor de estado oculto (`last_hidden_state`) tem o tamanho: **[batch_size,n_tokens,hidden_dim]**\n",
        "- ou seja, um vetor de 768 dimensões é retornado para cada um dos 6 tokens de entrada\n",
        "\n",
        "\n",
        "- Para **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">classificação de tarefas</mark>**\n",
        "    - é prática comum usar apenas o **estado oculto associado ao token [CLS]** como recurso de entrada"
      ],
      "metadata": {
        "id": "bQv5oRlLHctx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.last_hidden_state.size())\n",
        "print(outputs.last_hidden_state[:,0].size())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:14.49277Z",
          "iopub.execute_input": "2022-12-08T10:23:14.49309Z",
          "iopub.status.idle": "2022-12-08T10:23:14.498249Z",
          "shell.execute_reply.started": "2022-12-08T10:23:14.493062Z",
          "shell.execute_reply": "2022-12-08T10:23:14.49716Z"
        },
        "trusted": true,
        "id": "XrYn4BIRHctx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<span style='color:#F1A424'>Extraindo o último estado oculto do conjunto de dados</span>**\n",
        "\n",
        "- Sabemos como obter o último estado oculto para uma única string, vamos repetir o processo para todo o conjunto de dados usando `extract_hidden_states`"
      ],
      "metadata": {
        "id": "pWcsuIidHctx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "\n",
        "    # Place model inputs on the GPU\n",
        "    inputs = {k:v.to(device) for k,v in batch.items()\n",
        "              if k in tokenizer.model_input_names}\n",
        "\n",
        "    # Extract last hidden states\n",
        "    with torch.no_grad():\n",
        "        last_hidden_state = model(**inputs).last_hidden_state\n",
        "\n",
        "    # Return vector for [CLS] token\n",
        "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:14.499875Z",
          "iopub.execute_input": "2022-12-08T10:23:14.500324Z",
          "iopub.status.idle": "2022-12-08T10:23:14.507332Z",
          "shell.execute_reply.started": "2022-12-08T10:23:14.500287Z",
          "shell.execute_reply": "2022-12-08T10:23:14.506194Z"
        },
        "trusted": true,
        "id": "nY8_S5IdHctx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"torch\",\n",
        "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "emotions_encoded"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:14.508964Z",
          "iopub.execute_input": "2022-12-08T10:23:14.509587Z",
          "iopub.status.idle": "2022-12-08T10:23:14.521617Z",
          "shell.execute_reply.started": "2022-12-08T10:23:14.509551Z",
          "shell.execute_reply": "2022-12-08T10:23:14.520365Z"
        },
        "trusted": true,
        "id": "dibrPkrAHctx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract last hidden states (faster w/ GPU)\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)\n",
        "emotions_hidden[\"train\"].column_names"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:14.526917Z",
          "iopub.execute_input": "2022-12-08T10:23:14.527178Z",
          "iopub.status.idle": "2022-12-08T10:23:38.169037Z",
          "shell.execute_reply.started": "2022-12-08T10:23:14.527149Z",
          "shell.execute_reply": "2022-12-08T10:23:38.168173Z"
        },
        "trusted": true,
        "id": "-38lnz2UHcty"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<span style='color:#F1A424'>Criando a Matriz de Recursos</span>**\n",
        "\n",
        "- Nós temos **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">hidden states</mark>** associado a cada tweet, agora vamos treinar o classificador\n",
        "- Para fazer isso, precisamos da matriz de recursos para que possamos utilizá-la como entrada no modelo de aprendizado de máquina"
      ],
      "metadata": {
        "id": "UjNndCOoHcty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
        "print(f'Training Dataset: {X_train.shape}')\n",
        "print(f'Validation Dataset {X_valid.shape}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:23:38.172672Z",
          "iopub.execute_input": "2022-12-08T10:23:38.175019Z",
          "iopub.status.idle": "2022-12-08T10:23:38.376692Z",
          "shell.execute_reply.started": "2022-12-08T10:23:38.174982Z",
          "shell.execute_reply": "2022-12-08T10:23:38.375637Z"
        },
        "trusted": true,
        "id": "bBvqVr65Hcty"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check our dataset\n",
        "X_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:32:07.254199Z",
          "iopub.execute_input": "2022-12-08T10:32:07.254614Z",
          "iopub.status.idle": "2022-12-08T10:32:07.264427Z",
          "shell.execute_reply.started": "2022-12-08T10:32:07.254564Z",
          "shell.execute_reply": "2022-12-08T10:32:07.263214Z"
        },
        "trusted": true,
        "id": "T7hnNYmSHcty"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<span style='color:#F1A424'>Vizualizando os dados de treino</span>**\n",
        "\n",
        "- Podemos visualizar cada distribuição de classe que o modelo precisará separar em **<span style='color:#FFC300'>espaço de dimensão inferior</span>** (projeções em um espaço de menor dimensão)\n",
        "- Temos muitas **categorias sobrepostas** no espaço dimensional inferior (não significa que o modelo não será capaz de classificá-las em **<span style='color:#FFC300'>espaço dimensional superior</span>**)\n",
        "- Se forem separáveis ​​no espaço projetado, provavelmente serão separáveis ​​em **<span style='color:#FFC300'>espaço dimensional superior</span>**\n",
        "- Utilizaremos um **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">manifold learning</mark>** modelo não supervisionado **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">TSNE</mark>** (Vai demorar um pouco)"
      ],
      "metadata": {
        "id": "MddmVNVqHcty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Scale the data\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "\n",
        "# lower dimension transformation\n",
        "model = TSNE(n_components=2).fit(X_scaled)\n",
        "\n",
        "# Create a df of 2D embeddings\n",
        "df_embedding = pd.DataFrame(model.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_embedding[\"label\"] = y_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:38:49.895088Z",
          "iopub.execute_input": "2022-12-08T10:38:49.895447Z",
          "iopub.status.idle": "2022-12-08T10:41:38.138823Z",
          "shell.execute_reply.started": "2022-12-08T10:38:49.895413Z",
          "shell.execute_reply": "2022-12-08T10:41:38.137815Z"
        },
        "trusted": true,
        "id": "KXUOnGJmHctz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='whitegrid')\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
        "axes = axes.flatten()\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "\n",
        "    dict_embedding_sub = dict(tuple(df_embedding.groupby('label')))\n",
        "    df_embedding_sub = dict_embedding_sub[i]\n",
        "\n",
        "    axes[i].scatter(df_embedding_sub[\"X\"],\n",
        "                    df_embedding_sub[\"Y\"],\n",
        "                    lw=1,ec='k',alpha=0.2)\n",
        "\n",
        "    axes[i].set_title(f'{label}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-12-08T12:37:11.993692Z",
          "iopub.execute_input": "2022-12-08T12:37:11.994054Z",
          "iopub.status.idle": "2022-12-08T12:37:13.132302Z",
          "shell.execute_reply.started": "2022-12-08T12:37:11.99402Z",
          "shell.execute_reply": "2022-12-08T12:37:13.131508Z"
        },
        "trusted": true,
        "id": "ZWXt3JwtHctz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste gráfico podemos ver alguns padrões claros:\n",
        "- Para **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">positive emotions</mark>** (**<span style='color:#FFC300'>joy</span>** and **<span style='color:#FFC300'>love</span>**) estão bem separados do **<span style='color:#FFC300'>negative emotions</span>** e também compartilham um espaço semelhante\n",
        "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">Negative emotions</mark>** (**<span style='color:#FFC300'>sadness</span>**, **<span style='color:#FFC300'>anger</span>**, and **<span style='color:#FFC300'>fear</span>**) todos ocupam regiões muito semelhantes com distribuições ligeiramente variáveis **<span style='color:#FFC300'>espaço de dimensão inferior</span>**\n",
        "- Finalmente, **<span style='color:#FFC300'>surprise</span>** está um pouco espalhado por todo o **<span style='color:#FFC300'>espaço de dimensão inferior</span>**"
      ],
      "metadata": {
        "id": "ZQjCo2YcHctz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<span style='color:#F1A424'>Treinamento de um modelo de linha de base</span>**\n",
        "\n",
        "- Vamos usar estes **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">hidden states</mark>** para treinar um modelo **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">logistic regression</mark>**\n",
        "- Estamos lidando com um conjunto de dados multiclasse desbalanceado, então nosso modelo pode parecer melhor do que aleatório, mas na verdade é melhor, vamos comparar com um `DummyClassifier`\n",
        "- `DummyClassifier` pode ser usado para construir um classificador com heurísticas simples (escolhendo a classe majoritária/sempre desenhando uma classe aleatória),\n",
        "- Vamos escolher os mais frequentes (`strategy=\"most_frequent\"`) então temos um modelo de referência para comparação"
      ],
      "metadata": {
        "id": "a7c_bOSGHctz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "print(f'accuracy: {dummy_clf.score(X_valid, y_valid)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:51:45.431224Z",
          "iopub.execute_input": "2022-12-08T10:51:45.431577Z",
          "iopub.status.idle": "2022-12-08T10:51:45.440085Z",
          "shell.execute_reply.started": "2022-12-08T10:51:45.431539Z",
          "shell.execute_reply": "2022-12-08T10:51:45.438958Z"
        },
        "trusted": true,
        "id": "cjOafYoHHctz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "# We increase `max_iter` to guarantee convergence\n",
        "lr_clf = LR(max_iter = 2000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "print(f'accuracy: {lr_clf.score(X_valid, y_valid)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T10:53:07.864968Z",
          "iopub.execute_input": "2022-12-08T10:53:07.865363Z",
          "iopub.status.idle": "2022-12-08T10:55:26.147562Z",
          "shell.execute_reply.started": "2022-12-08T10:53:07.86533Z",
          "shell.execute_reply": "2022-12-08T10:55:26.146268Z"
        },
        "trusted": true,
        "id": "9Za26pJNHctz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Matriz de Confusão</span></b>\n",
        "\n",
        "- Nosso  **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">logistic regression</mark>** modelo com `DistilBERT` **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">embeddings</mark>**é significativamente melhor do que a linha de base `DummyClassifier`\n",
        "- Vamos verificar o **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">confusion matrix</mark>** do modelo **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">logistic regression</mark>**"
      ],
      "metadata": {
        "id": "IothcwSgHctz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_model, y_true, labels):\n",
        "    cm = confusion_matrix(y_true,y_model,normalize='true')\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot(ax=ax, colorbar=False)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "#     plt.axis('off')\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:04:17.616134Z",
          "iopub.execute_input": "2022-12-08T11:04:17.616732Z",
          "iopub.status.idle": "2022-12-08T11:04:18.044288Z",
          "shell.execute_reply.started": "2022-12-08T11:04:17.616678Z",
          "shell.execute_reply": "2022-12-08T11:04:18.043298Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Wvf15NCdHct0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">confusion matrix</mark>** podemos dizer que:\n",
        "\n",
        "- **<span style='color:#FFC300'>anger</span>**, **<span style='color:#FFC300'>fear</span>** & **<span style='color:#FFC300'>surprise</span>** frequentemente confundido com **<span style='color:#FFC300'>sadness</span>** podemos dizer que (0,29, 0,17 e 0,14) (observação que fizemos ao visualizar os embeddings)\n",
        "- **<span style='color:#FFC300'>love</span>** & **<span style='color:#FFC300'>surprise</span>** são frequentemente confundidos com **<span style='color:#FFC300'>joy</span>** (0.37 & 0.46)"
      ],
      "metadata": {
        "id": "5W9gtEMAHct0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'> 5.2 | </span>Transformadores de ajuste fino </b>\n",
        "\n",
        "- Com a abordagem de ajuste fino, não usamos o **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">hidden states</mark>** como recursos fixos, em vez disso, nós os treinamos a partir de um determinado estado do modelo\n",
        "- Isso requer que a cabeça de classificação seja diferenciável (rede neural para classificação)\n",
        "\n",
        "### <b><span style='color:#F1A424'>Carregando um modelo pré-treinado</span></b>\n",
        "\n",
        "- Nós carregaremos o mesmo **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>** modelo usando `model_ckpt` **\"distilbert-base-uncased\"**\n",
        "- Desta vez, porém, estaremos carregando `AutoModelForSequenceClassification` (nós usamos `AutoModel` quando extraímos recursos de incorporação)\n",
        "- `AutoModelForSequenceClassification` modelo tem um **<span style='color:#FFC300'>classification head</span>** sobre as saídas do modelo pré-treinado\n",
        "- Precisamos apenas especificar o **<span style='color:#FFC300'>number of labels</span>** o modelo tem que prever `num_labels`"
      ],
      "metadata": {
        "id": "-fGFt2STHct0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 6\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "model = (AutoModelForSequenceClassification\n",
        "         .from_pretrained(model_ckpt,\n",
        "                          num_labels=num_labels)\n",
        "         .to(device))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:10:21.040136Z",
          "iopub.execute_input": "2022-12-08T11:10:21.040512Z",
          "iopub.status.idle": "2022-12-08T11:10:23.974074Z",
          "shell.execute_reply.started": "2022-12-08T11:10:21.040479Z",
          "shell.execute_reply": "2022-12-08T11:10:23.973119Z"
        },
        "trusted": true,
        "id": "b-_k6uLWHct0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Definindo as métricas de desempenho</span></b>\n",
        "- Nós monitoraremos o `F1 score`  & `accuracy`, a função deve ser passada na classe `Trainer`\n",
        "\n"
      ],
      "metadata": {
        "id": "4HU2kcwsHct0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:41:06.255551Z",
          "iopub.execute_input": "2022-12-08T11:41:06.256256Z",
          "iopub.status.idle": "2022-12-08T11:41:06.261974Z",
          "shell.execute_reply.started": "2022-12-08T11:41:06.25622Z",
          "shell.execute_reply": "2022-12-08T11:41:06.260842Z"
        },
        "trusted": true,
        "id": "DOl0vlJHHct0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Parâmetros de treinamento</span></b>\n",
        "- Em seguida, precisamos definir os **parâmetros de treinamento** do modelo, o que pode ser feito usando `TrainingArguments`\n",
        "-Vamos treinar o **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>** modelo para **3 iterações** com uma **taxa de aprendizagem de 2e-5** e um **tamanho de lote de 64**"
      ],
      "metadata": {
        "id": "m3a0-k3gHct1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "bs = 64 # batch size\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // bs\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=3,             # number of training epochs\n",
        "                                  learning_rate=2e-5,             # model learning rate\n",
        "                                  per_device_train_batch_size=bs, # batch size\n",
        "                                  per_device_eval_batch_size=bs,  # batch size\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  report_to=\"none\",\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  push_to_hub=False,\n",
        "                                  log_level=\"error\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:43:28.129679Z",
          "iopub.execute_input": "2022-12-08T11:43:28.130736Z",
          "iopub.status.idle": "2022-12-08T11:43:28.138863Z",
          "shell.execute_reply.started": "2022-12-08T11:43:28.130684Z",
          "shell.execute_reply": "2022-12-08T11:43:28.137889Z"
        },
        "trusted": true,
        "id": "I46de2RlHct1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Modelo de treino</span></b>\n",
        "-Com os argumentos de treinamento definidos, precisamos definir o `Trainer` e comece a treinar com o método `train()`"
      ],
      "metadata": {
        "id": "UYROzxldHct1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import Trainer\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset=emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:43:35.476805Z",
          "iopub.execute_input": "2022-12-08T11:43:35.477167Z",
          "iopub.status.idle": "2022-12-08T11:47:06.284093Z",
          "shell.execute_reply.started": "2022-12-08T11:43:35.477136Z",
          "shell.execute_reply": "2022-12-08T11:47:06.282867Z"
        },
        "trusted": true,
        "id": "ApxXB_UaHct1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on Validation Dataset\n",
        "pred_output = trainer.predict(emotions_encoded[\"validation\"])\n",
        "pred_output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:50:41.122235Z",
          "iopub.execute_input": "2022-12-08T11:50:41.122617Z",
          "iopub.status.idle": "2022-12-08T11:50:44.025014Z",
          "shell.execute_reply.started": "2022-12-08T11:50:41.122568Z",
          "shell.execute_reply": "2022-12-08T11:50:44.024119Z"
        },
        "trusted": true,
        "id": "KjT1dcVOHct1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Output Predition: {pred_output.predictions.shape}')\n",
        "print(pred_output.predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:53:28.507573Z",
          "iopub.execute_input": "2022-12-08T11:53:28.508588Z",
          "iopub.status.idle": "2022-12-08T11:53:28.516563Z",
          "shell.execute_reply.started": "2022-12-08T11:53:28.508544Z",
          "shell.execute_reply": "2022-12-08T11:53:28.515286Z"
        },
        "trusted": true,
        "id": "HKzNFBv1Hct1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the predictions greedily using argmax (highest value of all classes)\n",
        "y_preds = np.argmax(pred_output.predictions,axis=1)\n",
        "print(f'Output Prediction:{y_preds.shape}')\n",
        "print(f'Predictions: {y_preds}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:54:48.54719Z",
          "iopub.execute_input": "2022-12-08T11:54:48.547643Z",
          "iopub.status.idle": "2022-12-08T11:54:48.558406Z",
          "shell.execute_reply.started": "2022-12-08T11:54:48.547579Z",
          "shell.execute_reply": "2022-12-08T11:54:48.557232Z"
        },
        "trusted": true,
        "id": "rDbBtyl4Hct2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Show metrics of last iteration\n",
        "pred_output.metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:48:08.349454Z",
          "iopub.execute_input": "2022-12-08T11:48:08.349931Z",
          "iopub.status.idle": "2022-12-08T11:48:08.357875Z",
          "shell.execute_reply.started": "2022-12-08T11:48:08.349889Z",
          "shell.execute_reply": "2022-12-08T11:48:08.356903Z"
        },
        "trusted": true,
        "id": "Wd0-aS9RHct2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_preds,y_valid,labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T11:55:09.833503Z",
          "iopub.execute_input": "2022-12-08T11:55:09.833892Z",
          "iopub.status.idle": "2022-12-08T11:55:10.16652Z",
          "shell.execute_reply.started": "2022-12-08T11:55:09.833858Z",
          "shell.execute_reply": "2022-12-08T11:55:10.165539Z"
        },
        "trusted": true,
        "id": "hyfBcRwmHct2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">confusion matrix</mark>** podemos dizer que:\n",
        "- O **fine-tune** abordagem (usando **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>**)  tem um desempenho muito melhor do que a simples extração **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">embedding</mark>** dados e treiná-los em um modelo de ML separado\n",
        "- **<span style='color:#FFC300'>love</span>** ainda é frequentemente confundido com **<span style='color:#FFC300'>joy</span>** (0.08), mas muito menos que a primeira abordagem\n",
        "- **<span style='color:#FFC300'>surprise</span>** é frequentemente confundido com **<span style='color:#FFC300'>joy</span>** bem como (0,09) ou medo (0,10), ambos também muito menores que a primeira abordagem"
      ],
      "metadata": {
        "id": "pa-lBJc7Hct2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>6 |</span></b> <b>ANÁLISE DE ERROS DO MODELO</b></div>\n",
        "\n",
        "### <b><span style='color:#F1A424'>Mapeamento de Valor de Perda</span></b>\n",
        "\n",
        "Deveríamos investigar um pouco mais a previsão dos nossos modelo\n",
        "- Uma técnica simples, mas poderosa, é classificar a validação por **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">model loss</mark>**\n",
        "- Podemos escrever uma função que retorna o **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">model loss</mark>**, juntamente com o rótulo previsto `forward_pass_with_label`"
      ],
      "metadata": {
        "id": "a0-_3g9FHct2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_label(batch):\n",
        "\n",
        "    # Place all input tensors on the same device as the model\n",
        "    inputs = {k:v.to(device) for k,v in batch.items()\n",
        "              if k in tokenizer.model_input_names}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        pred_label = torch.argmax(output.logits, axis=-1)\n",
        "        loss = cross_entropy(output.logits, batch[\"label\"].to(device),\n",
        "                             reduction=\"none\")\n",
        "\n",
        "    # Place outputs on CPU for compatibility with other dataset columns\n",
        "    return {\"loss\": loss.cpu().numpy(),\n",
        "            \"predicted_label\": pred_label.cpu().numpy()}\n",
        "\n",
        "# Convert our dataset back to PyTorch tensors\n",
        "emotions_encoded.set_format(\"torch\",\n",
        "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "# Compute loss values\n",
        "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(forward_pass_with_label,\n",
        "                                                                    batched=True,\n",
        "                                                                    batch_size=16)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:04:00.858126Z",
          "iopub.execute_input": "2022-12-08T12:04:00.858559Z",
          "iopub.status.idle": "2022-12-08T12:04:03.569018Z",
          "shell.execute_reply.started": "2022-12-08T12:04:00.858524Z",
          "shell.execute_reply": "2022-12-08T12:04:03.567801Z"
        },
        "trusted": true,
        "id": "9cL-cPYYHct2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b><span style='color:#F1A424'>Converter para DataFrame</span></b>\n",
        "\n",
        "- Crie um DataFrame com o texto, perdas, rótulos previstos/verdadeiros"
      ],
      "metadata": {
        "id": "MI7-hOQ8Hct3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"pandas\")\n",
        "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
        "df_test = emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\n",
        "df_test[\"predicted_label\"] = (df_test[\"predicted_label\"].apply(label_int2str))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:04:53.2985Z",
          "iopub.execute_input": "2022-12-08T12:04:53.298949Z",
          "iopub.status.idle": "2022-12-08T12:04:53.325452Z",
          "shell.execute_reply.started": "2022-12-08T12:04:53.298909Z",
          "shell.execute_reply": "2022-12-08T12:04:53.324503Z"
        },
        "trusted": true,
        "id": "GvfDnCfYHct3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Agora podemos classificar `emotions` codificado pelas perdas em ordem ascendente/descendente\n",
        "- Vamos analisar as amostras de dados com as **maiores perdas** (podemos ver que valores de perdas elevadas estão associados a previsões erradas)"
      ],
      "metadata": {
        "id": "DRfAz9jFHct3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_panel(df_test.sort_values(\"loss\", ascending=False))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:05:21.617079Z",
          "iopub.execute_input": "2022-12-08T12:05:21.617433Z",
          "iopub.status.idle": "2022-12-08T12:05:21.633055Z",
          "shell.execute_reply.started": "2022-12-08T12:05:21.6174Z",
          "shell.execute_reply": "2022-12-08T12:05:21.63199Z"
        },
        "trusted": true,
        "id": "sVHDANN-Hct3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_panel(df_test.sort_values(\"loss\", ascending=True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:07:55.383592Z",
          "iopub.execute_input": "2022-12-08T12:07:55.384104Z",
          "iopub.status.idle": "2022-12-08T12:07:55.401075Z",
          "shell.execute_reply.started": "2022-12-08T12:07:55.384067Z",
          "shell.execute_reply": "2022-12-08T12:07:55.400168Z"
        },
        "trusted": true,
        "id": "rQclETLeHct3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;overflow:hidden;background-color:#3b3745\"><b><span style='color:#F1A424'>7 |</span></b> <b>USANDO NOSSO MODELO</b></div>\n",
        "\n",
        "-Nós treinamos o modelo utilizando `AutoModelForSequenceClassification` que adicionou uma cabeça de classificação à base modelo **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:0.7\">DistilBERT</mark>**\n",
        "- Podemos utilizar o `pipeline` método quando precisamos fazer previsões de modelo em novos dados não semente\n",
        "- Digamos que temos novos dados não vistos:\n",
        "    - 'Assisti a um filme ontem à noite, foi brilhante'"
      ],
      "metadata": {
        "id": "72idlniUHct3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:20:27.087318Z",
          "iopub.execute_input": "2022-12-08T12:20:27.087723Z",
          "iopub.status.idle": "2022-12-08T12:20:27.587747Z",
          "shell.execute_reply.started": "2022-12-08T12:20:27.087688Z",
          "shell.execute_reply": "2022-12-08T12:20:27.586767Z"
        },
        "trusted": true,
        "id": "EeTdYSXUHct3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# load from previously saved model\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-emotion\")\n",
        "\n",
        "# New unseen by model data\n",
        "new_data = 'I watched a movie last night, it was quite brilliant'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:21:49.298239Z",
          "iopub.execute_input": "2022-12-08T12:21:49.298592Z",
          "iopub.status.idle": "2022-12-08T12:21:50.404567Z",
          "shell.execute_reply.started": "2022-12-08T12:21:49.298561Z",
          "shell.execute_reply": "2022-12-08T12:21:50.403577Z"
        },
        "trusted": true,
        "id": "SilAlvcQHct4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nosso modelo prevê `new_data` ser classificado como **rótulo 1** (**alegria**)"
      ],
      "metadata": {
        "id": "Gobntgq4Hct4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = classifier(new_data, return_all_scores=True)\n",
        "preds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:22:55.905119Z",
          "iopub.execute_input": "2022-12-08T12:22:55.905475Z",
          "iopub.status.idle": "2022-12-08T12:22:56.005471Z",
          "shell.execute_reply.started": "2022-12-08T12:22:55.905442Z",
          "shell.execute_reply": "2022-12-08T12:22:56.004479Z"
        },
        "trusted": true,
        "id": "y4mk9QPhHct4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preds[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:27:30.84932Z",
          "iopub.execute_input": "2022-12-08T12:27:30.84972Z",
          "iopub.status.idle": "2022-12-08T12:27:30.860021Z",
          "shell.execute_reply.started": "2022-12-08T12:27:30.849683Z",
          "shell.execute_reply": "2022-12-08T12:27:30.859085Z"
        },
        "trusted": true,
        "id": "mksUgC45Hct4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_preds = pd.DataFrame(preds)\n",
        "px.bar(x=labels,y=100*df_preds['score'],template='plotly_white')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T12:28:16.162031Z",
          "iopub.execute_input": "2022-12-08T12:28:16.163914Z",
          "iopub.status.idle": "2022-12-08T12:28:16.214984Z",
          "shell.execute_reply.started": "2022-12-08T12:28:16.163866Z",
          "shell.execute_reply": "2022-12-08T12:28:16.21393Z"
        },
        "trusted": true,
        "id": "Gh3BFYu0Hct4"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}